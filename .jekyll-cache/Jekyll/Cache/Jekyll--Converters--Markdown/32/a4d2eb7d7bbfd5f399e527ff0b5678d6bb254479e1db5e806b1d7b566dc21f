I"·<h1 id="research">Research</h1>

<!-- We seek to do cutting-edge, high-quality, and impactful research combining theory and practice. As such,  -->
<!-- We are closely collaborating with our industrial partners including Huawei, Alibaba Group, and Ant Group to solve real-world challenging problems in an effective and scalable way. Some of our recent projects are as follows. -->

<p><br />
<em>We are grateful to conduct research sponsored by NSFC, CCF and multiple industrial partners including Huawei, Alibaba Group, and Ant Group. Recently, we are working on the following exciting research themes.</em></p>

<!-- Here are some themes and techniques that we currently work on: -->
<!-- <br> -->

<!-- ### âœ… Deep Learning System Security -->
<p><br /></p>

<h4 id="theme-1-testing-verification-and-repair-of-ai-models-or-ai-based-systems"><strong><em>Theme 1: Testing, Verification and Repair of AI Models or AI-based Systems</em></strong></h4>
<!-- **[TOSEM 22, ICSE 21, TACAS 21, ISSTA 21, ASE 20, ICECCS 20, ICSE 19]: Testing, Verifying and Enhancing the Robustness of Deep Learning Models** -->

<p>For AI models (e.g., large language models of course or deep learning models in general) or AI-based systems (e.g., autonomous cars), we are working on <em>a systematic testing&gt;verification&gt;repair loop to comprehensively and automatically evaluate, identify and fix the potential risks hidden in multiple dimensions, e.g., robustness, fairness, safety and copyright.</em> This line of research is crucial for human being to be aware of, manage and mitigate the risks in the emergence of diverse AI and AI-based systems.</p>

<!-- including novel testing metrics correlated to robustness, test case generation methods, automatic verification and repair techniques to comprehensively test, verify and enhance the robustness of deep learning models deployed in various application scenarios, e.g., image classification, object detection and NLP. -->

<p><em>Related selected publications: [RA-L 24, TOSEM 24, ICSE 24, ICSE Demo 23, S&amp;P 22, ICSE 22, TOSEM 22, ICSE 21, TACAS 21, ISSTA 21, ASE 20, ICECCS 20, ICSE 19]</em></p>

<!-- ![](http://localhost:4000/images/respic/robust.png){: style="width: 700px; float: center; margin: 0px  10px"} -->
<!-- <br> -->
<p><br /></p>

<h4 id="theme-2-software-testing-or-verification-for-safety-critical-systems"><strong><em>Theme 2: Software Testing or Verification for Safety-critical Systems</em></strong></h4>
<!-- **[TOSEM 22, ICSE 21, TACAS 21, ISSTA 21, ASE 20, ICECCS 20, ICSE 19]: Testing, Verifying and Enhancing the Robustness of Deep Learning Models** -->

<p>Software is the core driving force for the safe operation of safety-critical systems (industrial control systems, autonomous systems, etc). It is thus crucial to formally verify the correctness of the software foundations (e.g., OS kernel or compilers) for safety-critical systems. 
<!-- We are building systematic methodologies and toolkits including novel testing metrics correlated to robustness, test case generation methods, automatic verification and repair techniques to comprehensively test, verify and enhance the robustness of deep learning models deployed in various application scenarios, e.g., image classification, object detection and NLP. --></p>

<p><em>Related publications: [CONFEST/FMICS 23, TSE 23, FITEE 22, IoT 22, TSE 21, ICSE 18, DSN 18, STTT 18, FM 18, FASE 17, FM 16]</em></p>

<!-- ![](http://localhost:4000/images/respic/robust.png){: style="width: 700px; float: center; margin: 0px  10px"} -->
<!-- <br> -->
<p><br /></p>

<h4 id="theme-3-ai-assisted-model-driven-engineering"><strong><em>Theme 3: AI-assisted Model Driven Engineering</em></strong></h4>

<!-- ##### ðŸ˜Š **[ISSTA 23, ICSE 22, TSE 21, ICSE 20]: Testing, Interpreting and Mitigating the Hidden Bias in Deep Learning**

We are building systematic fairness testing methodologies and toolkits specially designed for efficiently uncover, inteprete and mitigate various kinds of bias, e.g., individual discrimination and group discrimination, in deep learning models deployed in Alibaba's recommender system serving millions of people.

![](http://localhost:4000/images/respic/fairness.png){: style="width: 800px; float: center; margin: 0px  10px"}
<br>
<br>
 -->
<!-- ##### ðŸ˜Š **[ICSE 23, S&P 22]: Copyright Protection for Deep Learning Models**
We are building a copyright protection framework for deep learning models based on systematic testing, aiming to prove accurate and robust model copyright verification.

![](http://localhost:4000/images/respic/copyright_.png){: style="width: 700px; float: center; margin: 0px  10px"}
 -->

<!-- ### âœ… Cyber-physical System Security
<br>

##### ðŸ˜Š **[JCST 21, IoT 22]: Proactive Defense for Industrial Control Systems**

![](http://localhost:4000/images/respic/copyright_.png){: style="width: 700px; float: center; margin: 0px  10px"}
<br>

We are building a copyright protection framework for deep learning models based on systematic testing, aiming to prove accurate and robust model copyright verifications.


##### ðŸ˜Š **[TSE in submission]: Formal Semantics for Industrial Control Languages**

![](http://localhost:4000/images/respic/copyright_.png){: style="width: 700px; float: center; margin: 0px  10px"}
<br>

We are building a copyright protection framework for deep learning models based on systematic testing, aiming to prove accurate and robust model copyright verifications.


<br> -->

<!-- ![](http://localhost:4000/images/respic/nnrepair_.png){: style="width: 700px; float: center; margin: 0px  10px"}
<br>
**NN Repair.** We are building a NN(especially RNN) repair framework, aiming to repair incorrect behaviors provably.

![](http://localhost:4000/images/respic/ODsystem_.png){: style="width: 800px; float: center; margin: 0px  10px"}
<br>
**Object Detection System Security Testing.** By generating multiple test cases to expose the security vulnerablities of the object detection system, and designing test metrics to evaluate the security and robustness of the object detection system, finally we can build more security and more robust OD systems by retraining.

![](http://localhost:4000/images/respic/recommender_.png){: style="width: 800px; float: center; margin: 0px  10px"}
<br>
**DL Recommender System Fairness Testing:** We are building a DL recommender system testing framework to identify unfairness and find disadvantaged groups to improve the fairness of the original model.

![](http://localhost:4000/images/respic/robustness_.png){: style="width: 800px; float: center; margin: 0px  10px"}
<br>
**DL Robustness Testing.** We are building a DL testing framework that aims to enhance the model robustness against various attacks in a one-step way.

![](http://localhost:4000/images/respic/unlearning_.png){: style="width: 800px; float: center; margin: 0px  10px"}
<br>
**Certifiable Machine Unlearning.** We are building a certifiable machine unlearning framework that aims to guarantee the data to be forgotten and not damage model's performance. -->

<h4 id="-and-more">â€¦ and more.</h4>
:ET